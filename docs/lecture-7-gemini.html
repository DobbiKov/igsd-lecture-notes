<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Chapter 7: Eliminating the Unseen and Painting the Surfaces - IGSD Lecture Notes</title><meta property="og:title" content="Chapter 7: Eliminating the Unseen and Painting the Surfaces - IGSD Lecture Notes"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><link rel="stylesheet" href="/build/_assets/app-HG4THSM4.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><span class="text-md sm:text-xl tracking-tight sm:mr-5">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3iop:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode." aria-label="Toggle theme between light and dark mode."><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="IGSD Lecture Notes" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">IGSD Lecture Notes</a><a title="Lecture: Illumination and Textures" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/lecture-4-5-gemini">Lecture: Illumination and Textures</a><a title="Chapter 6: Snipping Away the Unseen - The Art of Clipping" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/lecture-6-gemini">Chapter 6: Snipping Away the Unseen - The Art of Clipping</a><a title="Chapter 7: Eliminating the Unseen and Painting the Surfaces" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg bg-blue-300/30 active" href="/lecture-7-gemini">Chapter 7: Eliminating the Unseen and Painting the Surfaces</a><a title="Methode du germe" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/methode-du-germe">Methode du germe</a><a title="Cohen Sutherland method" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/cohen-sutherland">Cohen Sutherland method</a><a title="Understanding atan2 function" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/atan2">Understanding atan2 function</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Exam questions" class="block break-words rounded py-2 grow cursor-pointer">Exam questions</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R13d8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R13d8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><a title="Visual Explanations" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/visual-explanations">Visual Explanations</a></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rd4fop:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Chapter 7: Eliminating the Unseen and Painting the Surfaces</h1><header class="mt-4 not-prose"><div><span class="font-semibold text-sm inline-block"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3kfop:" data-state="closed">Yehor KOROTENKO</button></span></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><h1 id="chapter-7-eliminating-the-unseen-and-painting-the-surfaces" class="relative group"><span class="heading-text">Chapter 7: Eliminating the Unseen and Painting the Surfaces</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#chapter-7-eliminating-the-unseen-and-painting-the-surfaces" title="Link to this Section" aria-label="Link to this Section">¶</a></h1><p>This chapter delves into two critical stages of the graphics pipeline, often grouped together due to their close relationship in the final rendering process: <strong>Élimination des Parties Cachées (Hidden Surface Removal)</strong> and <strong>Remplissage (Polygon Filling)</strong>. Following the transformations, illumination, and clipping stages discussed in previous lectures, these steps are crucial for generating the final, viewable image from a 3D scene. Hidden surface removal addresses the fundamental problem of visibility – determining which parts of the 3D objects are visible to the virtual camera and which are obscured by others. Once the visible surfaces are identified, polygon filling techniques come into play to render the interiors of these projected 2D polygons, providing a more realistic appearance to the objects.</p><h2 id="the-challenge-of-visibility-hidden-surface-removal" class="relative group"><span class="heading-text">The Challenge of Visibility: Hidden Surface Removal</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#the-challenge-of-visibility-hidden-surface-removal" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>In a 3D scene, objects are positioned at varying depths relative to the camera. When these objects are projected onto a 2D image plane, some surfaces will inevitably be occluded by others that are closer to the viewpoint. The process of <strong>hidden surface removal</strong> aims to identify and discard these occluded portions, ensuring that only the visible parts of the scene are rendered. Several algorithms have been developed to tackle this problem, each with its own trade-offs in terms of computational cost, memory usage, and suitability for different types of scenes. These algorithms can be broadly categorised into <strong>object-space</strong> and <strong>image-space</strong> approaches.</p><h3 id="object-space-algorithms" class="relative group"><span class="heading-text">Object-Space Algorithms</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#object-space-algorithms" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Object-space algorithms primarily work with the 3D geometry of the scene to determine visibility before projection or rasterisation.</p><ul><li><p><strong>Backface Culling:</strong> This is a relatively simple yet effective preliminary step. It leverages the fact that for closed, solid objects, faces whose normals point away from the viewer are generally not visible. By calculating the dot product of the surface normal and the vector to the viewpoint, faces with a positive or zero dot product (depending on convention) can be discarded. This technique can save approximately 50% of the processing time on average and has a low cost per polygon. However, it is only sufficient for single, convex objects.</p></li><li><p><strong>Painter’s Algorithm:</strong> Also known as the “depth-sort algorithm”, this method aims to render polygons in order of decreasing depth from the viewer. The idea is analogous to how a painter layers paint, with closer objects painted last, obscuring those behind them. The algorithm first sorts all the polygons in the scene based on their farthest z-coordinate (depth). It then draws the polygons starting from the farthest to the nearest. While conceptually simple, the Painter’s Algorithm faces challenges with overlapping polygons where a simple depth sort is insufficient to determine the correct visibility order. In such ambiguous cases, polygon splitting might be necessary.</p></li><li><p><strong>BSP Trees (Binary Space Partition Trees):</strong> This approach involves recursively subdividing the 3D space containing the scene’s primitives using a series of splitting planes. The result is a hierarchical tree structure (a Directed Acyclic Graph - DAG) that efficiently organises the scene. To render the scene, the BSP tree is traversed recursively. For each node, the position of the viewpoint relative to the splitting plane is determined. The subtree on the far side of the plane (relative to the viewer) is rendered first, then the primitive associated with the current node (if any), and finally the subtree on the near side. This traversal order ensures that objects are drawn back-to-front, effectively resolving visibility in many cases. However, constructing the BSP tree can be computationally intensive, and splitting primitives can increase the complexity of the scene.</p></li></ul><h3 id="image-space-algorithms" class="relative group"><span class="heading-text">Image-Space Algorithms</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#image-space-algorithms" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Image-space algorithms determine visibility after the scene has been projected onto the 2D image plane.</p><ul><li><p><strong>Warnock Subdivision Algorithm:</strong> This algorithm employs a “divide and conquer” strategy by recursively subdividing the image plane into smaller quadrants (a quadtree). For each quadrant, it determines the list of potentially visible polygons. In simple cases, such as when a quadrant contains no polygons or only a single polygon that entirely covers it, the rendering is straightforward. However, when a quadrant contains multiple overlapping polygons, the algorithm attempts to determine if one polygon obscures all others within that region based on depth. If a clear frontmost polygon cannot be identified, the quadrant is further subdivided, and the process is repeated. The subdivision continues until each quadrant is smaller than a pixel, at which point the colour of the closest polygon is assigned.</p></li><li><p><strong>Scan-Line Algorithms:</strong> These algorithms process the image row by row (scan line by scan line) to determine visibility. For each scan line, the algorithm identifies the intersections of the scan line with the edges of the projected polygons. These intersections divide the scan line into intervals. The visibility of the polygons within each interval is then determined by comparing their depths (z-values) at that particular scan line. Algorithms like <strong>Scan-Line-Watkins</strong> and <strong>Scan-Line-Z-buffer</strong> utilise this principle. The Scan-Line-Z-buffer method maintains a depth buffer (z-buffer) for the current scan line, storing the depth of the closest fragment encountered so far for each pixel along the line.</p></li><li><p><strong>Z-buffer Algorithm (Depth Buffer):</strong> The <strong>Z-buffer algorithm</strong>, introduced by Edwin Catmull, is one of the most widely used hidden surface removal techniques, particularly in hardware-accelerated graphics. It operates on a pixel-by-pixel basis and requires two buffers: a <strong>frame buffer</strong> to store the colour of each pixel and a <strong>z-buffer (depth buffer)</strong> to store the depth (z-value) of the object visible at each pixel. Initially, the z-buffer is filled with a value representing infinite depth, and the frame buffer is set to the background colour. As each polygon is rasterised (converted into fragments or pixels), the depth of the generated fragment is calculated. This depth is then compared to the value currently stored in the z-buffer at the corresponding pixel location. If the fragment’s depth is less than the stored depth (meaning it is closer to the viewer), the z-buffer is updated with the new depth, and the frame buffer is updated with the fragment’s colour. After processing all polygons, the frame buffer contains the final image with hidden surfaces correctly removed. The Z-buffer algorithm is relatively simple to implement, doesn’t require pre-sorting, and is highly parallelisable. However, it processes all polygons, even those that are entirely hidden, and has memory overhead for the z-buffer. It also doesn’t inherently handle transparency or inter-reflections correctly.</p></li></ul><h3 id="choosing-a-hidden-surface-removal-algorithm" class="relative group"><span class="heading-text">Choosing a Hidden Surface Removal Algorithm</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#choosing-a-hidden-surface-removal-algorithm" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>The choice of a particular hidden surface removal algorithm depends on various factors, including the complexity of the scene, the available hardware, and any specific rendering requirements beyond basic visibility. The Z-buffer algorithm is commonly provided by graphics libraries and hardware due to its simplicity and efficiency in many scenarios. Scan-line algorithms can be efficient when memory is limited or when specific rendering effects are desired that might be more easily integrated into the scan-line processing.</p><h2 id="filling-the-polygons-rendering-the-interiors" class="relative group"><span class="heading-text">Filling the Polygons: Rendering the Interiors</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#filling-the-polygons-rendering-the-interiors" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Once the visible polygons (or parts thereof after clipping) have been determined, the next step is to <strong>fill their interiors</strong> with the appropriate colours and attributes. This process, known as <strong>polygon filling</strong> or <strong>rasterisation</strong>, converts the 2D outline of the projected polygon into a set of discrete pixels on the screen and assigns them the calculated colours, often based on the illumination and shading models discussed previously.</p><p>A common approach to polygon filling is the <strong>scan-line fill algorithm</strong>. For each scan line that intersects the polygon, the algorithm determines the segments of the scan line that lie within the polygon’s boundaries. This typically involves finding the intersection points of the scan line with the polygon edges, sorting these intersection points along the x-axis, and then filling the pixels between pairs of consecutive intersection points. A <strong>parity rule</strong> is often used to determine whether a point lies inside or outside the polygon. As the scan line moves across the polygon, the colour of the pixels being filled is determined by interpolating the colour or intensity values across the polygon, potentially using techniques like Gouraud or Phong shading.</p><p>Another category of filling algorithms includes <strong>seed fill</strong> or <strong>flood fill</strong> algorithms. These algorithms start from an initial pixel known to be inside the polygon (the “seed”) and recursively or iteratively fill adjacent pixels that belong to the polygon’s interior based on a boundary condition (e.g., reaching an edge of a different colour or a predefined boundary).</p><p>Handling <strong>boundary conflicts</strong> is an important consideration in polygon filling. Due to the discrete nature of pixels and potential approximations in edge tracing, intersection points might not fall exactly on pixel centres. Robust filling algorithms often implement rules to ensure that adjacent polygons sharing an edge do not leave gaps or overlap in the final rendered image.</p><p>Expanding on:
<strong>Filling the Polygons: Rasterisation</strong></p><p>The terms “Filling the Polygons” and <strong>rasterisation</strong> essentially describe the process of converting the 2D projected primitives, which are often broken down into <strong>triangles</strong>, into a set of discrete pixels on the screen and assigning them colours. The goal is to render the interiors of these polygons, providing a more realistic and continuous appearance to the objects. The rasterisation pipeline takes 3D primitives as input and produces a bitmap image as output.</p><p><strong>Why Triangles?</strong></p><p>The sources highlight why triangles are the fundamental primitive for rasterisation:</p><ul><li>They can approximate any shape.</li><li>They are always planar with a well-defined normal vector.</li><li>It is easy to interpolate data across a triangle.</li></ul><p>Even points and lines are conceptually converted into triangles within the rasterisation pipeline.</p><p><strong>The Process of Rasterisation</strong></p><p>Rasterisation involves determining which pixels on the screen are covered by the projected 2D primitive (typically a triangle). For each pixel covered, the rasteriser also <strong>interpolates</strong> values known at the vertices of the primitive, such as colour and depth, to determine the corresponding values for that pixel (which is often referred to as a fragment).</p><p><strong>Polygon Filling Algorithms</strong></p><p>The sources discuss several methods for filling the projected polygons:</p><ul><li><p><strong>Testing Point Membership:</strong> This involves determining if a given point lies inside a polygon. Different approaches exist for convex and concave polygons.</p><ul><li><strong>Convex Polygons:</strong> One method involves determining “exterior” normals and checking if the point lies on the correct side of all the edges (defined by the normals). Another test involves checking the sign of the cross product of consecutive edge vectors; for a convex polygon, the sign should remain consistent during traversal.</li><li><strong>Concave Polygons:</strong> Concave polygons can change their traversal direction.</li><li><strong>Ray Casting (Number of Intersections Test):</strong> This involves drawing a ray from the point and counting the number of times it intersects the edges of the polygon. An odd number of intersections generally indicates the point is inside, while an even number indicates it’s outside. Care must be taken with edge cases like intersections at vertices or tangent edges.</li></ul></li><li><p><strong>Intersection Tests:</strong> These algorithms determine which parts of the screen are covered by the polygon by finding intersections with scan lines or other geometric entities.</p></li><li><p><strong>Scan-Line Algorithms:</strong> These algorithms process the image line by line (horizontally) within the bounding box of the polygon.</p><ul><li>For each scan line, the algorithm finds the intersections between the scan line and the edges of the polygon. This can be done by approximating the segments using a line tracing algorithm.</li><li>The intersection points are collected and organised, often in a linked list, and sorted by their x-coordinates.</li><li>A <strong>parity rule</strong> is then applied: as the scan line traverses the polygon, a parity counter is incremented each time an edge is crossed. Pixels are filled if the parity is odd, indicating they are inside the polygon.</li><li>To avoid gaps or overlaps along shared edges between polygons, algorithms need to handle boundary conflicts, often by considering points strictly inside the polygon.</li><li>For each involved side of the polygon and each processed scan line (<code>yi</code>), the calculation of the intersection requires the <code>ymax</code>, <code>xmin</code>, and the inverse of the slope (<code>dx/dy</code>) of the edge.</li></ul></li><li><p><strong>Region Filling (Seed Fill or Flood Fill):</strong> These algorithms operate on regions defined by a boundary. Starting from an interior “seed” pixel, the filling colour is recursively or iteratively propagated to neighbouring pixels until the boundary of the region is reached.</p></li></ul><p><strong>Integration with Shading</strong></p><p>The way polygons are filled is closely linked to the <strong>shading model</strong> being used. The shading model determines the colour of each pixel within the polygon. For example:</p><ul><li><strong>Flat Shading (Lambert Shading):</strong> A single illumination value is calculated for the entire polygon, often at the midpoint, using the face normal.</li><li><strong>Gouraud Shading:</strong> Illumination intensities are calculated at the vertices of the polygon and then bilinearly interpolated across the face. This helps to eliminate intensity discontinuities. The interpolation can be done edge by edge and then horizontally across the span. Gouraud shading is efficient and commonly implemented in graphics hardware.</li><li><strong>Phong Shading:</strong> Instead of interpolating intensities, Phong shading interpolates the surface normals at the vertices across the face. The illumination model is then applied at each pixel using the interpolated normal, resulting in more accurate specular highlights. This generally produces better results than Gouraud shading, especially for specular reflections, but is computationally more expensive.</li></ul><p>The interpolation process during rasterisation often uses techniques like <strong>linear interpolation</strong> and <strong>barycentric coordinates</strong>. Barycentric coordinates can be used to interpolate any vertex attribute (colour, texture coordinates, etc.) across the triangle during rasterisation by measuring the “distance” to each edge or by using the ratio of triangle areas. For perspective projections, a perspective-correct interpolation method is needed.</p><p><strong>Graphics Pipeline Integration</strong></p><p>Polygon filling (rasterisation) is a crucial step in the graphics pipeline. The 2D projected and clipped primitives are fed into the rasteriser. The output is a set of pixel fragments with interpolated attributes like colour and depth, which are then passed on to the visibility determination stage (e.g., using a Z-buffer) and eventually written to the frame buffer.</p><p>In summary, “Filling the Polygons” or rasterisation is the process of converting 2D geometric primitives into pixels on the screen, using various algorithms to determine which pixels are inside the polygon and interpolating attributes across its surface, influenced by the chosen shading model, to create the final rendered image.</p><h2 id="integration-with-the-graphics-pipeline" class="relative group"><span class="heading-text">Integration with the Graphics Pipeline</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#integration-with-the-graphics-pipeline" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Hidden surface removal and polygon filling are tightly integrated within the graphics pipeline. Following the projection and clipping stages, the 2D projected primitives are passed to the rasterisation stage, where polygon filling occurs. If a Z-buffer is employed, it works in conjunction with the rasterisation process. As each fragment of a polygon is generated during rasterisation, its depth is checked against the Z-buffer to determine visibility before its colour is written to the frame buffer. The output of these stages is the final 2D image, ready to be displayed.</p><h2 id="conclusion" class="relative group"><span class="heading-text">Conclusion</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#conclusion" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Lecture 7, covering hidden surface removal and polygon filling, addresses fundamental challenges in rendering realistic 3D graphics. By correctly determining which surfaces are visible and accurately filling the interiors of the projected polygons, these techniques are essential for creating the final image that represents the 3D scene from the camera’s perspective. The choice of algorithms for these stages significantly impacts the performance and visual quality of the rendered output, and a thorough understanding of these concepts is crucial for anyone working in the field of Informatique Graphique pour la Science des Données.</p><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/lecture-6-gemini"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">IGSD Lecture Notes</div>Chapter 6: Snipping Away the Unseen - The Art of Clipping</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/methode-du-germe"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">IGSD Lecture Notes</div>Methode du germe</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-IZFMW3M4.js"/><link rel="modulepreload" href="/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-QGLRP2PL.js"/><link rel="modulepreload" href="/build/_shared/chunk-CB3BH7WY.js"/><link rel="modulepreload" href="/build/routes/$-7JYT5576.js"/><script>window.__remixContext = {"url":"/lecture-7-gemini","state":{"loaderData":{"root":{"config":{"version":1,"myst":"1.3.25","options":{},"nav":[],"actions":[],"projects":[{"title":"IGSD Lecture Notes","authors":[{"id":"Yehor KOROTENKO","name":"Yehor KOROTENKO"}],"id":"a889e744-0d66-400f-ad19-a1b68892e6f3","toc":[{"file":"README.md"},{"file":"lecture-4-5-gemini.md"},{"file":"lecture-6-gemini.md"},{"file":"lecture-7-gemini.md"},{"file":"methode-du-germe.md"},{"file":"cohen-sutherland.md"},{"file":"atan2.md"},{"children":[{"file":"exam_questions/transformation-matrix-for-turning.md"},{"file":"exam_questions/temp-exo-proj.md"},{"file":"exam_questions/cohen-sutherland-clipping.md"},{"file":"exam_questions/methode-du-germe.md"}],"title":"Exam questions"},{"file":"visual-explanations.ipynb"}],"exports":[],"bibliography":[],"index":"readme","pages":[{"slug":"lecture-4-5-gemini","title":"Lecture: Illumination and Textures","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"lecture-6-gemini","title":"Chapter 6: Snipping Away the Unseen - The Art of Clipping","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"lecture-7-gemini","title":"Chapter 7: Eliminating the Unseen and Painting the Surfaces","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"methode-du-germe","title":"Methode du germe","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"cohen-sutherland","title":"Cohen Sutherland method","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"atan2","title":"Understanding atan2 function","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":1,"title":"Exam questions"},{"slug":"transformation-matrix-for-turning","title":"Transformation matrix for the rotation around the line from the given points","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"temp-exo-proj","title":"Projecting point onto the screen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"cohen-sutherland-clipping","title":"Analyzing Cohen-Sutherland Algorithm","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"methode-du-germe-1","title":"Solution pour l’exo avec methode du germe","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"visual-explanations","title":"Visual Explanations","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"version":1,"myst":"1.3.25","options":{},"nav":[],"actions":[],"projects":[{"title":"IGSD Lecture Notes","authors":[{"id":"Yehor KOROTENKO","name":"Yehor KOROTENKO"}],"id":"a889e744-0d66-400f-ad19-a1b68892e6f3","toc":[{"file":"README.md"},{"file":"lecture-4-5-gemini.md"},{"file":"lecture-6-gemini.md"},{"file":"lecture-7-gemini.md"},{"file":"methode-du-germe.md"},{"file":"cohen-sutherland.md"},{"file":"atan2.md"},{"children":[{"file":"exam_questions/transformation-matrix-for-turning.md"},{"file":"exam_questions/temp-exo-proj.md"},{"file":"exam_questions/cohen-sutherland-clipping.md"},{"file":"exam_questions/methode-du-germe.md"}],"title":"Exam questions"},{"file":"visual-explanations.ipynb"}],"exports":[],"bibliography":[],"index":"readme","pages":[{"slug":"lecture-4-5-gemini","title":"Lecture: Illumination and Textures","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"lecture-6-gemini","title":"Chapter 6: Snipping Away the Unseen - The Art of Clipping","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"lecture-7-gemini","title":"Chapter 7: Eliminating the Unseen and Painting the Surfaces","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"methode-du-germe","title":"Methode du germe","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"cohen-sutherland","title":"Cohen Sutherland method","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"atan2","title":"Understanding atan2 function","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":1,"title":"Exam questions"},{"slug":"transformation-matrix-for-turning","title":"Transformation matrix for the rotation around the line from the given points","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"temp-exo-proj","title":"Projecting point onto the screen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"cohen-sutherland-clipping","title":"Analyzing Cohen-Sutherland Algorithm","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"methode-du-germe-1","title":"Solution pour l’exo avec methode du germe","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"visual-explanations","title":"Visual Explanations","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}]},"page":{"version":1,"kind":"Article","sha256":"99591e3f9f7cb1c4207218796277cd10feb3eaea4d29c8e5c29cb9b5182783ec","slug":"lecture-7-gemini","location":"/lecture-7-gemini.md","dependencies":[],"frontmatter":{"title":"Chapter 7: Eliminating the Unseen and Painting the Surfaces","content_includes_title":true,"authors":[{"id":"Yehor KOROTENKO","name":"Yehor KOROTENKO"}],"exports":[{"format":"md","filename":"lecture-7-gemini.md","url":"/build/lecture-7-gemini-2dd3f30ee67ef3d8e4561f11b0fe6d31.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"heading","depth":1,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Chapter 7: Eliminating the Unseen and Painting the Surfaces","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SgxaWxFqvq"}],"identifier":"chapter-7-eliminating-the-unseen-and-painting-the-surfaces","label":"Chapter 7: Eliminating the Unseen and Painting the Surfaces","html_id":"chapter-7-eliminating-the-unseen-and-painting-the-surfaces","implicit":true,"key":"u8bdzT2AUW"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This chapter delves into two critical stages of the graphics pipeline, often grouped together due to their close relationship in the final rendering process: ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"KiAhwCfnOz"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Élimination des Parties Cachées (Hidden Surface Removal)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"uFofDc77xq"}],"key":"FAdLGUWuNh"},{"type":"text","value":" and ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Pm5tY62Iul"},{"type":"strong","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Remplissage (Polygon Filling)","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"MgRlk2DRCs"}],"key":"kWNTj6W5HG"},{"type":"text","value":". Following the transformations, illumination, and clipping stages discussed in previous lectures, these steps are crucial for generating the final, viewable image from a 3D scene. Hidden surface removal addresses the fundamental problem of visibility – determining which parts of the 3D objects are visible to the virtual camera and which are obscured by others. Once the visible surfaces are identified, polygon filling techniques come into play to render the interiors of these projected 2D polygons, providing a more realistic appearance to the objects.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"YZeXpR2HIK"}],"key":"CBNk628a9s"},{"type":"heading","depth":2,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The Challenge of Visibility: Hidden Surface Removal","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"OEELdFDP7M"}],"identifier":"the-challenge-of-visibility-hidden-surface-removal","label":"The Challenge of Visibility: Hidden Surface Removal","html_id":"the-challenge-of-visibility-hidden-surface-removal","implicit":true,"key":"u7QvszoJEv"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"In a 3D scene, objects are positioned at varying depths relative to the camera. When these objects are projected onto a 2D image plane, some surfaces will inevitably be occluded by others that are closer to the viewpoint. The process of ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"c3xEnV7NvH"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"hidden surface removal","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"TcLNvTC5xO"}],"key":"po9RbsRFca"},{"type":"text","value":" aims to identify and discard these occluded portions, ensuring that only the visible parts of the scene are rendered. Several algorithms have been developed to tackle this problem, each with its own trade-offs in terms of computational cost, memory usage, and suitability for different types of scenes. These algorithms can be broadly categorised into ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ncNnICHp5O"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"object-space","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"A6idQHSIY0"}],"key":"JlYYJlo7Js"},{"type":"text","value":" and ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"trMbKm0blB"},{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"image-space","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"dzezb0wCxZ"}],"key":"dici0v3fse"},{"type":"text","value":" approaches.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"huCG2kA2yP"}],"key":"YnMF6ge8OI"},{"type":"heading","depth":3,"position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"Object-Space Algorithms","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"klKR8t1lYR"}],"identifier":"object-space-algorithms","label":"Object-Space Algorithms","html_id":"object-space-algorithms","implicit":true,"key":"HNz0OiYkQK"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"children":[{"type":"text","value":"Object-space algorithms primarily work with the 3D geometry of the scene to determine visibility before projection or rasterisation.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"Jij3gLzvZL"}],"key":"jQmedhwl53"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":13,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"strong","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Backface Culling:","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"rJi3viWymH"}],"key":"W4QAVLaIkx"},{"type":"text","value":" This is a relatively simple yet effective preliminary step. It leverages the fact that for closed, solid objects, faces whose normals point away from the viewer are generally not visible. By calculating the dot product of the surface normal and the vector to the viewpoint, faces with a positive or zero dot product (depending on convention) can be discarded. This technique can save approximately 50% of the processing time on average and has a low cost per polygon. However, it is only sufficient for single, convex objects.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"t6b1FUuyUt"}],"key":"wNyeYsPkCU"}],"key":"uDOfJcVNkT"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"strong","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Painter’s Algorithm:","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"W73fKzYuy9"}],"key":"OVGxQkFFzC"},{"type":"text","value":" Also known as the “depth-sort algorithm”, this method aims to render polygons in order of decreasing depth from the viewer. The idea is analogous to how a painter layers paint, with closer objects painted last, obscuring those behind them. The algorithm first sorts all the polygons in the scene based on their farthest z-coordinate (depth). It then draws the polygons starting from the farthest to the nearest. While conceptually simple, the Painter’s Algorithm faces challenges with overlapping polygons where a simple depth sort is insufficient to determine the correct visibility order. In such ambiguous cases, polygon splitting might be necessary.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"tSKLTUhyeN"}],"key":"R0UbyG5MeB"}],"key":"TzUR3iacfh"},{"type":"listItem","spread":true,"position":{"start":{"line":17,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"strong","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"children":[{"type":"text","value":"BSP Trees (Binary Space Partition Trees):","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"Uo2eqEJbNp"}],"key":"R4nrw9IUYh"},{"type":"text","value":" This approach involves recursively subdividing the 3D space containing the scene’s primitives using a series of splitting planes. The result is a hierarchical tree structure (a Directed Acyclic Graph - DAG) that efficiently organises the scene. To render the scene, the BSP tree is traversed recursively. For each node, the position of the viewpoint relative to the splitting plane is determined. The subtree on the far side of the plane (relative to the viewer) is rendered first, then the primitive associated with the current node (if any), and finally the subtree on the near side. This traversal order ensures that objects are drawn back-to-front, effectively resolving visibility in many cases. However, constructing the BSP tree can be computationally intensive, and splitting primitives can increase the complexity of the scene.","position":{"start":{"line":17,"column":1},"end":{"line":17,"column":1}},"key":"Xe3TQtSuiW"}],"key":"KAaxjD07NP"}],"key":"lHBLCbY8af"}],"key":"hZLMXGNeuB"},{"type":"heading","depth":3,"position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"text","value":"Image-Space Algorithms","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"P3ADHryMbk"}],"identifier":"image-space-algorithms","label":"Image-Space Algorithms","html_id":"image-space-algorithms","implicit":true,"key":"zRBiUgbbCj"},{"type":"paragraph","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"Image-space algorithms determine visibility after the scene has been projected onto the 2D image plane.","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"gbtoKScZE9"}],"key":"kVAlpClCSr"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":23,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":23,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"strong","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"text","value":"Warnock Subdivision Algorithm:","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"g2TtunU6O8"}],"key":"Xsl7NNfb6K"},{"type":"text","value":" This algorithm employs a “divide and conquer” strategy by recursively subdividing the image plane into smaller quadrants (a quadtree). For each quadrant, it determines the list of potentially visible polygons. In simple cases, such as when a quadrant contains no polygons or only a single polygon that entirely covers it, the rendering is straightforward. However, when a quadrant contains multiple overlapping polygons, the algorithm attempts to determine if one polygon obscures all others within that region based on depth. If a clear frontmost polygon cannot be identified, the quadrant is further subdivided, and the process is repeated. The subdivision continues until each quadrant is smaller than a pixel, at which point the colour of the closest polygon is assigned.","position":{"start":{"line":23,"column":1},"end":{"line":23,"column":1}},"key":"YWDYKDaBcl"}],"key":"Tmo0crzvzm"}],"key":"tMnZmwLFVE"},{"type":"listItem","spread":true,"position":{"start":{"line":25,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"strong","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Scan-Line Algorithms:","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"IbWzdG58vL"}],"key":"su1lKEWAW8"},{"type":"text","value":" These algorithms process the image row by row (scan line by scan line) to determine visibility. For each scan line, the algorithm identifies the intersections of the scan line with the edges of the projected polygons. These intersections divide the scan line into intervals. The visibility of the polygons within each interval is then determined by comparing their depths (z-values) at that particular scan line. Algorithms like ","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"JIoOdO97jB"},{"type":"strong","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Scan-Line-Watkins","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"YB4kXjTe05"}],"key":"gkPSl5qIC7"},{"type":"text","value":" and ","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"PpD0butYvw"},{"type":"strong","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"children":[{"type":"text","value":"Scan-Line-Z-buffer","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"p89KaMajMS"}],"key":"EahzK0GtE1"},{"type":"text","value":" utilise this principle. The Scan-Line-Z-buffer method maintains a depth buffer (z-buffer) for the current scan line, storing the depth of the closest fragment encountered so far for each pixel along the line.","position":{"start":{"line":25,"column":1},"end":{"line":25,"column":1}},"key":"U2h7SEAvbf"}],"key":"wNbTDzfdQy"}],"key":"fIW4HV7pfZ"},{"type":"listItem","spread":true,"position":{"start":{"line":27,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"strong","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Z-buffer Algorithm (Depth Buffer):","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"R4PXL1zwpS"}],"key":"df1vrNv0mu"},{"type":"text","value":" The ","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"oyqxuoCXaz"},{"type":"strong","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"Z-buffer algorithm","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"v1oDtLk8GL"}],"key":"qyTVxFBpyn"},{"type":"text","value":", introduced by Edwin Catmull, is one of the most widely used hidden surface removal techniques, particularly in hardware-accelerated graphics. It operates on a pixel-by-pixel basis and requires two buffers: a ","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"yfQUE5LrrR"},{"type":"strong","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"frame buffer","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"JMs1aupMzz"}],"key":"oYcG9MjBrn"},{"type":"text","value":" to store the colour of each pixel and a ","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"y0htcuE5Un"},{"type":"strong","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"children":[{"type":"text","value":"z-buffer (depth buffer)","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"ehdRWNeqYl"}],"key":"U5caFKnD0E"},{"type":"text","value":" to store the depth (z-value) of the object visible at each pixel. Initially, the z-buffer is filled with a value representing infinite depth, and the frame buffer is set to the background colour. As each polygon is rasterised (converted into fragments or pixels), the depth of the generated fragment is calculated. This depth is then compared to the value currently stored in the z-buffer at the corresponding pixel location. If the fragment’s depth is less than the stored depth (meaning it is closer to the viewer), the z-buffer is updated with the new depth, and the frame buffer is updated with the fragment’s colour. After processing all polygons, the frame buffer contains the final image with hidden surfaces correctly removed. The Z-buffer algorithm is relatively simple to implement, doesn’t require pre-sorting, and is highly parallelisable. However, it processes all polygons, even those that are entirely hidden, and has memory overhead for the z-buffer. It also doesn’t inherently handle transparency or inter-reflections correctly.","position":{"start":{"line":27,"column":1},"end":{"line":27,"column":1}},"key":"IvZvDipgHX"}],"key":"MiNVSzKhVq"}],"key":"FraMOIU7mS"}],"key":"xUwGsE9spj"},{"type":"heading","depth":3,"position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"children":[{"type":"text","value":"Choosing a Hidden Surface Removal Algorithm","position":{"start":{"line":29,"column":1},"end":{"line":29,"column":1}},"key":"Zv3iqaMidh"}],"identifier":"choosing-a-hidden-surface-removal-algorithm","label":"Choosing a Hidden Surface Removal Algorithm","html_id":"choosing-a-hidden-surface-removal-algorithm","implicit":true,"key":"hQU7aDonZr"},{"type":"paragraph","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"children":[{"type":"text","value":"The choice of a particular hidden surface removal algorithm depends on various factors, including the complexity of the scene, the available hardware, and any specific rendering requirements beyond basic visibility. The Z-buffer algorithm is commonly provided by graphics libraries and hardware due to its simplicity and efficiency in many scenarios. Scan-line algorithms can be efficient when memory is limited or when specific rendering effects are desired that might be more easily integrated into the scan-line processing.","position":{"start":{"line":31,"column":1},"end":{"line":31,"column":1}},"key":"B6IDKNVsjW"}],"key":"QH0oUCYAVs"},{"type":"heading","depth":2,"position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"children":[{"type":"text","value":"Filling the Polygons: Rendering the Interiors","position":{"start":{"line":33,"column":1},"end":{"line":33,"column":1}},"key":"L9vUhCJGpl"}],"identifier":"filling-the-polygons-rendering-the-interiors","label":"Filling the Polygons: Rendering the Interiors","html_id":"filling-the-polygons-rendering-the-interiors","implicit":true,"key":"J4N6iUiN5B"},{"type":"paragraph","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"Once the visible polygons (or parts thereof after clipping) have been determined, the next step is to ","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"p36Vl0beNX"},{"type":"strong","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"fill their interiors","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"IxWS3nRDdb"}],"key":"CLB3hofxVJ"},{"type":"text","value":" with the appropriate colours and attributes. This process, known as ","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"UJo6gK85nK"},{"type":"strong","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"polygon filling","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"pTmLmSjiDH"}],"key":"hr7p1D2Kt0"},{"type":"text","value":" or ","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"K45WgCi3it"},{"type":"strong","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"text","value":"rasterisation","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"jKwhLMejFQ"}],"key":"d1klyWlhoF"},{"type":"text","value":", converts the 2D outline of the projected polygon into a set of discrete pixels on the screen and assigns them the calculated colours, often based on the illumination and shading models discussed previously.","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"esYnWXp1fG"}],"key":"Adl6GT8Oe3"},{"type":"paragraph","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"A common approach to polygon filling is the ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"I4uvesdKdc"},{"type":"strong","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"scan-line fill algorithm","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"jPT0lCfhMg"}],"key":"yYBiV9Bd63"},{"type":"text","value":". For each scan line that intersects the polygon, the algorithm determines the segments of the scan line that lie within the polygon’s boundaries. This typically involves finding the intersection points of the scan line with the polygon edges, sorting these intersection points along the x-axis, and then filling the pixels between pairs of consecutive intersection points. A ","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"pW1vrN84aP"},{"type":"strong","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"children":[{"type":"text","value":"parity rule","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"jnxNoZZdnY"}],"key":"fQ65fZ7CD0"},{"type":"text","value":" is often used to determine whether a point lies inside or outside the polygon. As the scan line moves across the polygon, the colour of the pixels being filled is determined by interpolating the colour or intensity values across the polygon, potentially using techniques like Gouraud or Phong shading.","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"rySZXiblzD"}],"key":"DgQPxzu4Ik"},{"type":"paragraph","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"Another category of filling algorithms includes ","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"xj74mAXd3e"},{"type":"strong","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"seed fill","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"SJM05SscgH"}],"key":"lbpnW36oVC"},{"type":"text","value":" or ","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"iFN8oUkfQX"},{"type":"strong","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"flood fill","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"D3f4kEyvAu"}],"key":"WB0iRVKrML"},{"type":"text","value":" algorithms. These algorithms start from an initial pixel known to be inside the polygon (the “seed”) and recursively or iteratively fill adjacent pixels that belong to the polygon’s interior based on a boundary condition (e.g., reaching an edge of a different colour or a predefined boundary).","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"J9OffllxOC"}],"key":"B40TeraqqV"},{"type":"paragraph","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"text","value":"Handling ","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"MpzEsjdhYg"},{"type":"strong","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"text","value":"boundary conflicts","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"yBArJmYhSL"}],"key":"SQoaLeDRyF"},{"type":"text","value":" is an important consideration in polygon filling. Due to the discrete nature of pixels and potential approximations in edge tracing, intersection points might not fall exactly on pixel centres. Robust filling algorithms often implement rules to ensure that adjacent polygons sharing an edge do not leave gaps or overlap in the final rendered image.","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"cP31FJLuoa"}],"key":"jNFOCLk9at"},{"type":"paragraph","position":{"start":{"line":43,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"text","value":"Expanding on:\n","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"oJP0Mzzxei"},{"type":"strong","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"Filling the Polygons: Rasterisation","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"jhaS5eZiSs"}],"key":"wQI36JGqYC"}],"key":"OlJqcv3Och"},{"type":"paragraph","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"The terms “Filling the Polygons” and ","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"CnZYjs02aR"},{"type":"strong","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"rasterisation","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"l32MBFldJz"}],"key":"LDi0GMZHCi"},{"type":"text","value":" essentially describe the process of converting the 2D projected primitives, which are often broken down into ","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"qEDq7a61iT"},{"type":"strong","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"text","value":"triangles","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"V8pUhcDrga"}],"key":"it1rYyrD3o"},{"type":"text","value":", into a set of discrete pixels on the screen and assigning them colours. The goal is to render the interiors of these polygons, providing a more realistic and continuous appearance to the objects. The rasterisation pipeline takes 3D primitives as input and produces a bitmap image as output.","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"sORskAuApv"}],"key":"bX6KTjJD5j"},{"type":"paragraph","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"strong","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"children":[{"type":"text","value":"Why Triangles?","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"mHoFhPE5mg"}],"key":"SeeMErlnzZ"}],"key":"L88Uu9CAbE"},{"type":"paragraph","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"children":[{"type":"text","value":"The sources highlight why triangles are the fundamental primitive for rasterisation:","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"U1PhjlbJf1"}],"key":"u14g3n8emA"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":52,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"They can approximate any shape.","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"q5OrqjzyFf"}],"key":"jbassh0iGq"},{"type":"listItem","spread":true,"position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"children":[{"type":"text","value":"They are always planar with a well-defined normal vector.","position":{"start":{"line":53,"column":1},"end":{"line":53,"column":1}},"key":"IeMzpS3Cu2"}],"key":"PlTH6t9gg6"},{"type":"listItem","spread":true,"position":{"start":{"line":54,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"text","value":"It is easy to interpolate data across a triangle.","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"grooqg6Arl"}],"key":"sj60kaW6gb"}],"key":"g9idYzS0Su"},{"type":"paragraph","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"children":[{"type":"text","value":"Even points and lines are conceptually converted into triangles within the rasterisation pipeline.","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"hZstsNaQKC"}],"key":"Z8PLYXUuVg"},{"type":"paragraph","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"strong","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"The Process of Rasterisation","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"MOY5rWh8uW"}],"key":"YoAHjXITyy"}],"key":"iuBvBE07tH"},{"type":"paragraph","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"text","value":"Rasterisation involves determining which pixels on the screen are covered by the projected 2D primitive (typically a triangle). For each pixel covered, the rasteriser also ","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"NYHsOMk6cO"},{"type":"strong","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"text","value":"interpolates","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"Gin2HKFDmz"}],"key":"MwFz7rLUur"},{"type":"text","value":" values known at the vertices of the primitive, such as colour and depth, to determine the corresponding values for that pixel (which is often referred to as a fragment).","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"rsJHbouk0A"}],"key":"Nb6fcKFFo8"},{"type":"paragraph","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"strong","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"text","value":"Polygon Filling Algorithms","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"Hgwpj4TSF4"}],"key":"Lil9bX6XbS"}],"key":"LmYHEvmTZl"},{"type":"paragraph","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"text","value":"The sources discuss several methods for filling the projected polygons:","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"QKWz4KnQnZ"}],"key":"QB3AXsaEpG"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":66,"column":1},"end":{"line":81,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":66,"column":1},"end":{"line":70,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"strong","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"text","value":"Testing Point Membership:","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"NG9tk3hyyA"}],"key":"aO39DdRWpG"},{"type":"text","value":" This involves determining if a given point lies inside a polygon. Different approaches exist for convex and concave polygons.","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"rztzsTNJJp"}],"key":"BnS5vB3Dxb"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":67,"column":1},"end":{"line":70,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"strong","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"text","value":"Convex Polygons:","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"B386A7m2fT"}],"key":"JCYEnFOIhT"},{"type":"text","value":" One method involves determining “exterior” normals and checking if the point lies on the correct side of all the edges (defined by the normals). Another test involves checking the sign of the cross product of consecutive edge vectors; for a convex polygon, the sign should remain consistent during traversal.","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"vEvSBmFpLH"}],"key":"EOUSHjgYnF"},{"type":"listItem","spread":true,"position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"strong","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"text","value":"Concave Polygons:","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"BNFlQBoDYG"}],"key":"D3dkJpCE8G"},{"type":"text","value":" Concave polygons can change their traversal direction.","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"l2xSntBsrf"}],"key":"wXju5SWrTr"},{"type":"listItem","spread":true,"position":{"start":{"line":69,"column":1},"end":{"line":70,"column":1}},"children":[{"type":"strong","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"children":[{"type":"text","value":"Ray Casting (Number of Intersections Test):","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"ozaC5XfMYb"}],"key":"p2BM5KXNue"},{"type":"text","value":" This involves drawing a ray from the point and counting the number of times it intersects the edges of the polygon. An odd number of intersections generally indicates the point is inside, while an even number indicates it’s outside. Care must be taken with edge cases like intersections at vertices or tangent edges.","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"Zow3szW9Ik"}],"key":"z7F7XamXci"}],"key":"siCriBtzlR"}],"key":"t34XWhWOHv"},{"type":"listItem","spread":true,"position":{"start":{"line":71,"column":1},"end":{"line":72,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"children":[{"type":"strong","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"children":[{"type":"text","value":"Intersection Tests:","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"g3ScPGiuxe"}],"key":"w0k7NxnuEB"},{"type":"text","value":" These algorithms determine which parts of the screen are covered by the polygon by finding intersections with scan lines or other geometric entities.","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"LruaIPKGgG"}],"key":"VbaK0qLfzT"}],"key":"biTmLjf844"},{"type":"listItem","spread":true,"position":{"start":{"line":73,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"children":[{"type":"strong","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"children":[{"type":"text","value":"Scan-Line Algorithms:","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"key":"Vy95S9jhjn"}],"key":"m0Ev2oNK3x"},{"type":"text","value":" These algorithms process the image line by line (horizontally) within the bounding box of the polygon.","position":{"start":{"line":73,"column":1},"end":{"line":73,"column":1}},"key":"bDO8hEnRoR"}],"key":"u3iEM87nbR"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":74,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"text","value":"For each scan line, the algorithm finds the intersections between the scan line and the edges of the polygon. This can be done by approximating the segments using a line tracing algorithm.","position":{"start":{"line":74,"column":1},"end":{"line":74,"column":1}},"key":"NTusderxZM"}],"key":"JfU2ladRGs"},{"type":"listItem","spread":true,"position":{"start":{"line":75,"column":1},"end":{"line":75,"column":1}},"children":[{"type":"text","value":"The intersection points are collected and organised, often in a linked list, and sorted by their x-coordinates.","position":{"start":{"line":75,"column":1},"end":{"line":75,"column":1}},"key":"wkNZaOFrTs"}],"key":"jZVRoirUep"},{"type":"listItem","spread":true,"position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"children":[{"type":"text","value":"A ","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"dAoTpQeWhu"},{"type":"strong","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"children":[{"type":"text","value":"parity rule","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"zohWGcPfX1"}],"key":"uZ7UzuvXWe"},{"type":"text","value":" is then applied: as the scan line traverses the polygon, a parity counter is incremented each time an edge is crossed. Pixels are filled if the parity is odd, indicating they are inside the polygon.","position":{"start":{"line":76,"column":1},"end":{"line":76,"column":1}},"key":"DAazHq4owi"}],"key":"nmpyzxaNjL"},{"type":"listItem","spread":true,"position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"children":[{"type":"text","value":"To avoid gaps or overlaps along shared edges between polygons, algorithms need to handle boundary conflicts, often by considering points strictly inside the polygon.","position":{"start":{"line":77,"column":1},"end":{"line":77,"column":1}},"key":"my88n4rPsq"}],"key":"TFJFicQGsi"},{"type":"listItem","spread":true,"position":{"start":{"line":78,"column":1},"end":{"line":79,"column":1}},"children":[{"type":"text","value":"For each involved side of the polygon and each processed scan line (","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"mScFXCTjBq"},{"type":"inlineCode","value":"yi","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"Gjdaz7xyuY"},{"type":"text","value":"), the calculation of the intersection requires the ","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"dA5EgUH8Pu"},{"type":"inlineCode","value":"ymax","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"SO3hgOmbIm"},{"type":"text","value":", ","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"MOoNCZxcA4"},{"type":"inlineCode","value":"xmin","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"om9FzmxpkG"},{"type":"text","value":", and the inverse of the slope (","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"sW840ZGDkk"},{"type":"inlineCode","value":"dx/dy","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"PjI3qCOEoy"},{"type":"text","value":") of the edge.","position":{"start":{"line":78,"column":1},"end":{"line":78,"column":1}},"key":"VbeLiVdB4Q"}],"key":"GL03m7lKo2"}],"key":"WwiVTGD5xX"}],"key":"VYg8wO3THI"},{"type":"listItem","spread":true,"position":{"start":{"line":80,"column":1},"end":{"line":81,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"children":[{"type":"strong","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"children":[{"type":"text","value":"Region Filling (Seed Fill or Flood Fill):","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"key":"zEO12OwQoz"}],"key":"gXw2g2c0RB"},{"type":"text","value":" These algorithms operate on regions defined by a boundary. Starting from an interior “seed” pixel, the filling colour is recursively or iteratively propagated to neighbouring pixels until the boundary of the region is reached.","position":{"start":{"line":80,"column":1},"end":{"line":80,"column":1}},"key":"I5kGVgNqG4"}],"key":"OpbH243QSE"}],"key":"ZQztIegpht"}],"key":"JIjdYBJ7xC"},{"type":"paragraph","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"children":[{"type":"strong","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"children":[{"type":"text","value":"Integration with Shading","position":{"start":{"line":82,"column":1},"end":{"line":82,"column":1}},"key":"l2XrdYL3qh"}],"key":"hUIJYv3DEy"}],"key":"FswmDvtZRt"},{"type":"paragraph","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"children":[{"type":"text","value":"The way polygons are filled is closely linked to the ","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"key":"ivJLQUDVN0"},{"type":"strong","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"children":[{"type":"text","value":"shading model","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"key":"GOAeFyAztG"}],"key":"h7h7SOXS7y"},{"type":"text","value":" being used. The shading model determines the colour of each pixel within the polygon. For example:","position":{"start":{"line":84,"column":1},"end":{"line":84,"column":1}},"key":"F5mhJf1DKv"}],"key":"pvvXvVwBmd"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":86,"column":1},"end":{"line":89,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"children":[{"type":"strong","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"children":[{"type":"text","value":"Flat Shading (Lambert Shading):","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"key":"MncD9dz5xA"}],"key":"pTypZpz5lM"},{"type":"text","value":" A single illumination value is calculated for the entire polygon, often at the midpoint, using the face normal.","position":{"start":{"line":86,"column":1},"end":{"line":86,"column":1}},"key":"yLcEYfUkAo"}],"key":"v9pMyMzO6U"},{"type":"listItem","spread":true,"position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"children":[{"type":"strong","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"children":[{"type":"text","value":"Gouraud Shading:","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"key":"kyuSoqM15t"}],"key":"IZFrYiHgno"},{"type":"text","value":" Illumination intensities are calculated at the vertices of the polygon and then bilinearly interpolated across the face. This helps to eliminate intensity discontinuities. The interpolation can be done edge by edge and then horizontally across the span. Gouraud shading is efficient and commonly implemented in graphics hardware.","position":{"start":{"line":87,"column":1},"end":{"line":87,"column":1}},"key":"RJOGYBMmUk"}],"key":"c8G2H8wple"},{"type":"listItem","spread":true,"position":{"start":{"line":88,"column":1},"end":{"line":89,"column":1}},"children":[{"type":"strong","position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"children":[{"type":"text","value":"Phong Shading:","position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"key":"ClyuwELo9N"}],"key":"ZiiacYt3sQ"},{"type":"text","value":" Instead of interpolating intensities, Phong shading interpolates the surface normals at the vertices across the face. The illumination model is then applied at each pixel using the interpolated normal, resulting in more accurate specular highlights. This generally produces better results than Gouraud shading, especially for specular reflections, but is computationally more expensive.","position":{"start":{"line":88,"column":1},"end":{"line":88,"column":1}},"key":"RBT2ItXjmD"}],"key":"BVLuxEE8Ly"}],"key":"mSmVlunJZX"},{"type":"paragraph","position":{"start":{"line":90,"column":1},"end":{"line":90,"column":1}},"children":[{"type":"text","value":"The interpolation process during rasterisation often uses techniques like ","position":{"start":{"line":90,"column":1},"end":{"line":90,"column":1}},"key":"NaxfSgJYNu"},{"type":"strong","position":{"start":{"line":90,"column":1},"end":{"line":90,"column":1}},"children":[{"type":"text","value":"linear interpolation","position":{"start":{"line":90,"column":1},"end":{"line":90,"column":1}},"key":"nyOqsxCTXr"}],"key":"Xmh8yO3WiA"},{"type":"text","value":" and ","position":{"start":{"line":90,"column":1},"end":{"line":90,"column":1}},"key":"cnuKae16MM"},{"type":"strong","position":{"start":{"line":90,"column":1},"end":{"line":90,"column":1}},"children":[{"type":"text","value":"barycentric coordinates","position":{"start":{"line":90,"column":1},"end":{"line":90,"column":1}},"key":"doL02hbRTc"}],"key":"LHf3sQBz4B"},{"type":"text","value":". Barycentric coordinates can be used to interpolate any vertex attribute (colour, texture coordinates, etc.) across the triangle during rasterisation by measuring the “distance” to each edge or by using the ratio of triangle areas. For perspective projections, a perspective-correct interpolation method is needed.","position":{"start":{"line":90,"column":1},"end":{"line":90,"column":1}},"key":"UuWCatoYPq"}],"key":"MGmqA02xSZ"},{"type":"paragraph","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"children":[{"type":"strong","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"children":[{"type":"text","value":"Graphics Pipeline Integration","position":{"start":{"line":92,"column":1},"end":{"line":92,"column":1}},"key":"win7H9SzJu"}],"key":"H9vumboBYo"}],"key":"Liyek5gIAY"},{"type":"paragraph","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"children":[{"type":"text","value":"Polygon filling (rasterisation) is a crucial step in the graphics pipeline. The 2D projected and clipped primitives are fed into the rasteriser. The output is a set of pixel fragments with interpolated attributes like colour and depth, which are then passed on to the visibility determination stage (e.g., using a Z-buffer) and eventually written to the frame buffer.","position":{"start":{"line":94,"column":1},"end":{"line":94,"column":1}},"key":"Y5eHfb0eoI"}],"key":"yIfYVoIeuG"},{"type":"paragraph","position":{"start":{"line":96,"column":1},"end":{"line":96,"column":1}},"children":[{"type":"text","value":"In summary, “Filling the Polygons” or rasterisation is the process of converting 2D geometric primitives into pixels on the screen, using various algorithms to determine which pixels are inside the polygon and interpolating attributes across its surface, influenced by the chosen shading model, to create the final rendered image.","position":{"start":{"line":96,"column":1},"end":{"line":96,"column":1}},"key":"LBIcWGG52W"}],"key":"ChpYvqoshH"},{"type":"heading","depth":2,"position":{"start":{"line":98,"column":1},"end":{"line":98,"column":1}},"children":[{"type":"text","value":"Integration with the Graphics Pipeline","position":{"start":{"line":98,"column":1},"end":{"line":98,"column":1}},"key":"S1qHodpCGR"}],"identifier":"integration-with-the-graphics-pipeline","label":"Integration with the Graphics Pipeline","html_id":"integration-with-the-graphics-pipeline","implicit":true,"key":"EYtibP9NwJ"},{"type":"paragraph","position":{"start":{"line":100,"column":1},"end":{"line":100,"column":1}},"children":[{"type":"text","value":"Hidden surface removal and polygon filling are tightly integrated within the graphics pipeline. Following the projection and clipping stages, the 2D projected primitives are passed to the rasterisation stage, where polygon filling occurs. If a Z-buffer is employed, it works in conjunction with the rasterisation process. As each fragment of a polygon is generated during rasterisation, its depth is checked against the Z-buffer to determine visibility before its colour is written to the frame buffer. The output of these stages is the final 2D image, ready to be displayed.","position":{"start":{"line":100,"column":1},"end":{"line":100,"column":1}},"key":"Y0NAhEGVNI"}],"key":"zbgrL6OW0K"},{"type":"heading","depth":2,"position":{"start":{"line":102,"column":1},"end":{"line":102,"column":1}},"children":[{"type":"text","value":"Conclusion","position":{"start":{"line":102,"column":1},"end":{"line":102,"column":1}},"key":"eJvDTuFQHG"}],"identifier":"conclusion","label":"Conclusion","html_id":"conclusion","implicit":true,"key":"WPPD79e9lR"},{"type":"paragraph","position":{"start":{"line":104,"column":1},"end":{"line":104,"column":1}},"children":[{"type":"text","value":"Lecture 7, covering hidden surface removal and polygon filling, addresses fundamental challenges in rendering realistic 3D graphics. By correctly determining which surfaces are visible and accurately filling the interiors of the projected polygons, these techniques are essential for creating the final image that represents the 3D scene from the camera’s perspective. The choice of algorithms for these stages significantly impacts the performance and visual quality of the rendered output, and a thorough understanding of these concepts is crucial for anyone working in the field of Informatique Graphique pour la Science des Données.","position":{"start":{"line":104,"column":1},"end":{"line":104,"column":1}},"key":"Jx4NQZtCD4"}],"key":"qK88K9u9Fh"}],"key":"jTOfo6rE4P"}],"key":"hO6byvIjb2"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Chapter 6: Snipping Away the Unseen - The Art of Clipping","url":"/lecture-6-gemini","group":"IGSD Lecture Notes"},"next":{"title":"Methode du germe","url":"/methode-du-germe","group":"IGSD Lecture Notes"}}},"domain":"http://localhost:3000"},"project":{"title":"IGSD Lecture Notes","authors":[{"id":"Yehor KOROTENKO","name":"Yehor KOROTENKO"}],"id":"a889e744-0d66-400f-ad19-a1b68892e6f3","toc":[{"file":"README.md"},{"file":"lecture-4-5-gemini.md"},{"file":"lecture-6-gemini.md"},{"file":"lecture-7-gemini.md"},{"file":"methode-du-germe.md"},{"file":"cohen-sutherland.md"},{"file":"atan2.md"},{"children":[{"file":"exam_questions/transformation-matrix-for-turning.md"},{"file":"exam_questions/temp-exo-proj.md"},{"file":"exam_questions/cohen-sutherland-clipping.md"},{"file":"exam_questions/methode-du-germe.md"}],"title":"Exam questions"},{"file":"visual-explanations.ipynb"}],"exports":[],"bibliography":[],"index":"readme","pages":[{"slug":"lecture-4-5-gemini","title":"Lecture: Illumination and Textures","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"lecture-6-gemini","title":"Chapter 6: Snipping Away the Unseen - The Art of Clipping","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"lecture-7-gemini","title":"Chapter 7: Eliminating the Unseen and Painting the Surfaces","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"methode-du-germe","title":"Methode du germe","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"cohen-sutherland","title":"Cohen Sutherland method","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"atan2","title":"Understanding atan2 function","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":1,"title":"Exam questions"},{"slug":"transformation-matrix-for-turning","title":"Transformation matrix for the rotation around the line from the given points","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"temp-exo-proj","title":"Projecting point onto the screen","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"cohen-sutherland-clipping","title":"Analyzing Cohen-Sutherland Algorithm","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"methode-du-germe-1","title":"Solution pour l’exo avec methode du germe","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"visual-explanations","title":"Visual Explanations","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-B4831781.js";
import * as route0 from "/build/root-QGLRP2PL.js";
import * as route1 from "/build/routes/$-7JYT5576.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>